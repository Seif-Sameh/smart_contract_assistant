"""Safety guardrails and disclaimers for generated answers."""

from typing import Tuple

HARMFUL_PATTERNS = [
    "how to commit fraud",
    "how to evade taxes illegally",
    "how to forge documents",
    "how to launder money",
    "how to breach contract illegally",
    "how to hide assets",
    "illegal activity",
    "commit crime",
]

LEGAL_DISCLAIMER = (
    "\n\n---\n"
    "**Disclaimer:** This response is generated by an AI assistant and is provided "
    "for informational purposes only. It does not constitute legal advice. "
    "Please consult a qualified legal professional for advice specific to your situation."
)


def check_safety(query: str) -> Tuple[bool, str]:
    """Check whether a query is safe to process.

    Args:
        query: The user's query string.

    Returns:
        Tuple of (is_safe: bool, reason: str).
        If is_safe is False, reason explains why the query was blocked.
    """
    lower_query = query.lower()
    for pattern in HARMFUL_PATTERNS:
        if pattern in lower_query:
            return False, f"Query contains potentially harmful content: '{pattern}'"
    return True, "Query is safe."


def apply_disclaimer(answer: str) -> str:
    """Append a legal disclaimer to an answer.

    Args:
        answer: The generated answer string.

    Returns:
        Answer string with legal disclaimer appended.
    """
    return answer + LEGAL_DISCLAIMER


def check_factuality(answer: str) -> str:
    """Check and annotate the factuality of an answer.

    If the answer indicates insufficient information, return it as-is.
    Otherwise, wrap it with a note about grounding.

    Args:
        answer: The generated answer string.

    Returns:
        The answer string, possibly annotated.
    """
    if "I don't have enough information" in answer:
        return answer

    return answer
